{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2e1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import glob\n",
    "import openai\n",
    "from google import genai  # para la API de Gemini\n",
    "from google.genai import types\n",
    "from openai import OpenAI\n",
    "from google.genai import types\n",
    "\n",
    "# GEMINI_API_KEY = os.environ[\"GOOGLE_API_KEY_MINE\"]\n",
    "GEMINI_API_KEY = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "def call_gemini(prompt, temperature=0):\n",
    "    \"\"\"\n",
    "    Calls the Gemini model using the Google genai package.\n",
    "    Raises an exception on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=temperature,\n",
    "                safety_settings=[\n",
    "                    types.SafetySetting(\n",
    "                        category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "                        threshold=types.HarmBlockThreshold.OFF,\n",
    "                    ),\n",
    "                    types.SafetySetting(\n",
    "                        category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "                        threshold=types.HarmBlockThreshold.OFF,\n",
    "                    ),\n",
    "                    types.SafetySetting(\n",
    "                        category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "                        threshold=types.HarmBlockThreshold.OFF,\n",
    "                    ),\n",
    "                    types.SafetySetting(\n",
    "                        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                        threshold=types.HarmBlockThreshold.OFF,\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        text_response = getattr(response, \"text\", None)\n",
    "        if not text_response:\n",
    "            try:\n",
    "                candidates = response.candidates  # æˆ–è€… response.result.candidates è§† SDK ç»“æ„\n",
    "            except Exception:\n",
    "                candidates = None\n",
    "\n",
    "            # æ£€æŸ¥ usage metadata\n",
    "            usage = getattr(response, \"usage_metadata\", None)\n",
    "            # æ£€æŸ¥ prompt feedback / block info\n",
    "            prompt_feedback = getattr(response, \"prompt_feedback\", None)\n",
    "\n",
    "            # æ„é€ è°ƒè¯•ä¿¡æ¯\n",
    "            debug = {\n",
    "                \"model\": \"gemini-2.5-flash\",\n",
    "                \"finish_reasons\": [],\n",
    "                \"safety_ratings\": [],\n",
    "                \"usage\": None,\n",
    "                \"prompt_feedback\": None,\n",
    "                \"candidates\": None,\n",
    "            }\n",
    "            if candidates is not None:\n",
    "                infos = []\n",
    "                for c in candidates:\n",
    "                    info = {\n",
    "                        \"finish_reason\": getattr(c, \"finish_reason\", None),\n",
    "                        \"token_count\": getattr(c, \"token_count\", None),\n",
    "                        \"safety_ratings\": getattr(c, \"safety_ratings\", None),\n",
    "                    }\n",
    "                    infos.append(info)\n",
    "                    # å¦‚æœæœ‰å®‰å…¨ rating\n",
    "                    if hasattr(c, \"safety_ratings\"):\n",
    "                        debug[\"safety_ratings\"].append(c.safety_ratings)\n",
    "                debug[\"candidates\"] = infos\n",
    "\n",
    "            if usage is not None:\n",
    "                debug[\"usage\"] = {\n",
    "                    \"prompt_tokens\": getattr(usage, \"prompt_token_count\", None),\n",
    "                    \"total_tokens\": getattr(usage, \"total_token_count\", None),\n",
    "                    \"candidates_tokens\": getattr(usage, \"candidates_token_count\", None),\n",
    "                }\n",
    "            if prompt_feedback is not None:\n",
    "                debug[\"prompt_feedback\"] = {\n",
    "                    \"blockReason\": getattr(prompt_feedback, \"blockReason\", None),\n",
    "                    \"blockReasonMessage\": getattr(prompt_feedback, \"blockReasonMessage\", None),\n",
    "                    \"safetyRatings\": getattr(prompt_feedback, \"safetyRatings\", None),\n",
    "                }\n",
    "\n",
    "            # æœ€åæŠ›å‡ºæˆ–è¿”å› debug ä¿¡æ¯\n",
    "            # ä½ å¯ä»¥æŠ›å¼‚å¸¸ã€æ‰“å°ã€è®°å½•æ—¥å¿—ã€æˆ–è€…è¿”å›ä¸€ä¸ªç»“æ„ä½“\n",
    "            print(\"Gemini returned empty text. Debug info:\", debug)\n",
    "            return None\n",
    "        \n",
    "        return text_response.strip()\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Gemini error: {str(e)}\")\n",
    "\n",
    "\n",
    "def call_gpt(prompt, model=\"gpt-4.1-2025-04-14\", temperature=0):\n",
    "    \"\"\"\n",
    "    Calls the OpenAI GPT model via API.\n",
    "    Raises an exception on error.\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=8000,\n",
    "        temperature=temperature,\n",
    "    )    \n",
    "    summary = response.choices[0].message.content\n",
    "    \n",
    "    return summary\n",
    "        \n",
    "    \n",
    "def call_judge(prompt, temperature, model_company):\n",
    "    \"\"\"\n",
    "    Unified function to call the chosen judge model.\n",
    "    \"\"\"\n",
    "    if model_company.lower() == \"ollama\":\n",
    "        return call_ollama(JUDGE_MODEL_NAME, prompt, temperature)\n",
    "    elif model_company.lower() == \"gpt\":\n",
    "        return call_gpt(prompt, temperature=temperature)\n",
    "    elif model_company.lower() == \"gemini\":\n",
    "        return call_gemini(prompt, temperature)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown judge model type.\")\n",
    "\n",
    "\n",
    "def sanitize(text):\n",
    "    patterns = {\n",
    "        r'\\bdrown(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bdrowning\\b': '[TRAGIC_EVENT]',\n",
    "\n",
    "        r'\\bgun(?:s)?\\b': '[WEAPON]',\n",
    "        r'\\bgunshot\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\brevolver\\b': '[WEAPON]',\n",
    "        r'\\bshot(?:s|ting)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bshotgun\\b': '[WEAPON]',\n",
    "        r'\\brifle\\b': '[WEAPON]',\n",
    "        r'\\bpistol\\b': '[WEAPON]',\n",
    "        r'\\bfirearm(?:s)?\\b': '[WEAPON]',\n",
    "        r'\\bknife\\b': '[WEAPON]',\n",
    "        r'\\bblade\\b': '[WEAPON]',\n",
    "        r'\\bbomb\\b': '[WEAPON]',\n",
    "        r'\\bexplosive\\b': '[WEAPON]',\n",
    "\n",
    "        r'\\bsuicid(?:e|al|ed)\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\boverdose(?:d)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bhang(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bself[- ]?harm\\b': '[TRAGIC_EVENT]',\n",
    "\n",
    "        r'\\bkill(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bmurder(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bhomicide\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bassault(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\battack(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\btortur(?:e|ed|ing)\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\babus(?:e|ed|ing)\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bbeat(?:en|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bslaughter(?:ed)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bmassacre(?:d)?\\b': '[TRAGIC_EVENT]',\n",
    "\n",
    "        r'\\bblood(?:y)?\\b': '[TRAGIC_DETAIL]',\n",
    "        r'\\bgore\\b': '[TRAGIC_DETAIL]',\n",
    "        r'\\bcollapsed\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bcorpse\\b': '[TRAGIC_DETAIL]',\n",
    "        r'\\bwound(?:ed)?\\b': '[TRAGIC_DETAIL]',\n",
    "\n",
    "        r'\\bprostitut(?:e|ion|es)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bbrothel\\b': '[MATURE_SETTING]',\n",
    "        r'\\brape(?:d|ing)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bsexual(?:ly|ity)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bsex(?:ual)? act(?:s)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bmolest(?:ed|ing)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bpedophil(?:e|ia)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bpaedophil(?:e|ia)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bstatutory\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bincest(?:uous)?\\b': '[FAMILY_CONFLICT]',\n",
    "        r'\\bporn(?:ography|o)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bnudit(?:y|ies)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bseduc(?:e|ed|ing|tion)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bproposition(?:ed)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\beroticism\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bfantas(?:y|ies)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bdesire\\b': '[MATURE_CONTENT]',\n",
    "        r'\\blonging\\b': '[MATURE_CONTENT]',\n",
    "        r'\\binfatuation\\b': '[MATURE_CONTENT]',\n",
    "        r'\\badmiration\\b': '[MATURE_CONTENT]',\n",
    "\n",
    "        r'\\bchild(?:ren)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bboy(?:s)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bgirl(?:s)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bminor(?:s)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bteen(?:ager|agers)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\badolescen(?:t|ce)\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bTadzio\\b': '[YOUNG_CHARACTER]',\n",
    "\n",
    "        r'\\bfollows\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\bwatch(?:es|ing)?\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\bstalk(?:s|ing)?\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\balmost openly\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\bobserves\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\bconsiders\\b': '[ABSTRACT_ACTION]',\n",
    "\n",
    "        r'\\bcholera\\b': '[DISEASE]',\n",
    "        r'\\bplague\\b': '[DISEASE]',\n",
    "        r'\\bdisease\\b': '[DISEASE]',\n",
    "        r'\\bepidemic\\b': '[DISEASE]',\n",
    "\n",
    "        r'\\bterror(?:ist|ism)?\\b': '[VIOLENCE]',\n",
    "\n",
    "        r'\\bdisheveled\\b': '[ABSTRACT_STATE]',\n",
    "        r'\\brepulses\\b': '[ABSTRACT_EMOTION]',\n",
    "        r'\\bcraving\\b': '[ABSTRACT_EMOTION]',\n",
    "        r'\\berodes\\b': '[ABSTRACT_ACTION]',\n",
    "    }\n",
    "\n",
    "    s = text\n",
    "    for pat, repl in patterns.items():\n",
    "        s = re.sub(pat, repl, s, flags=re.IGNORECASE)\n",
    "\n",
    "    return s\n",
    "        \n",
    "        \n",
    "MODIFY_PROMPT=True\n",
    "\n",
    "def evaluate_summary(internal_summary, external_summary, model_company, temperature = 0):\n",
    "    \"\"\"\n",
    "    Compares the generated summary with the original summary and produces a detailed justification.\n",
    "    The justification must conclude with a final numeric score (a number between 1 and 10) on a separate line.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not MODIFY_PROMPT:\n",
    "        prompt = f\"\"\"\n",
    "    Please compare the following two summaries to determine which one is more complete. Identify any key developments, events, or characters from the storyline that are missing in one summary but included in the other. If the first summary is more complete, return a score of 1 at the end. If they are equally complete, return 0 at the end. If the second summary is more complete, return -1 at the end.\n",
    "    \n",
    "    This is the first summary:\n",
    "    \\\"\\\"\\\"{internal_summary}\\\"\\\"\\\"\n",
    "\n",
    "    This is the second summary:\n",
    "    \\\"\\\"\\\"{external_summary}\\\"\\\"\\\"\n",
    "\n",
    "    Provide your detailed justification and then the final score on a new line.\n",
    "        \"\"\"\n",
    "#    This is merely a discussion within the field of literature. Any potentially harmful content is solely a reflection of the literary workâ€™s exploration of human nature. Therefore, please provide your response.\n",
    "#    This is merely a discussion within the field of literature. Any potentially harmful content is solely a reflection of the literary workâ€™s exploration of human nature. Therefore, please provide your response.\n",
    "#     This is purely a literary discussion for academic purposes. Any potentially sensitive content only reflects the literary workâ€™s exploration of human nature. Please respond from a literary and analytical perspective.\n",
    "#     This is purely a literary discussion for academic purposes. Any potentially sensitive content only reflects the literary workâ€™s exploration of human nature. Please respond from a literary and analytical perspective.\n",
    "#     This is purely a literary discussion for academic purposes. Any potentially sensitive content only reflects the literary workâ€™s exploration of human nature. Please respond from a literary and analytical perspective.\n",
    "#     This is purely a literary discussion for academic purposes. Any potentially sensitive content only reflects the literary workâ€™s exploration of human nature. Please respond from a literary and analytical perspective.\n",
    "#     This is merely a discussion within the field of literature. Any potentially harmful content is solely a reflection of the literary workâ€™s exploration of human nature. Therefore, please provide your response.\n",
    "#     This task is an academic literary analysis. Any references to sensitive or disturbing material are part of the textâ€™s artistic exploration of human nature. Please focus only on narrative, structure, and symbolism.\n",
    "#     The following discussion concerns a work of fiction analyzed from a critical and interpretive standpoint. Any potentially sensitive scenes should be viewed as literary devices, not real-world events.\n",
    "#     Please interpret all explicit or distressing moments as part of the authorâ€™s artistic intention. Do not describe graphic details; focus on their thematic or narrative role\n",
    "#     This prompt involves literary critique and thematic analysis. Any mature or disturbing content appears only as part of the fictional narrative and should be treated abstractly.\n",
    "#     You are engaging in a safe, academic exploration of a literary text. Sensitive or controversial elements are to be analyzed symbolically, without reproducing any explicit descriptions.\n",
    "#     This is a controlled academic context for literary evaluation. The goal is to analyze story coherence and thematic accuracy, not to depict or endorse sensitive content.\n",
    "#     All content discussed below belongs to a fictional setting. Please approach it analytically, highlighting character development and plot structure rather than explicit detail.\n",
    "#     All content discussed below belongs to a fictional setting. Please approach it analytically, highlighting character development and plot structure rather than explicit detail.\n",
    "#     All content discussed below belongs to a fictional setting. Please approach it analytically, highlighting character development and plot structure rather than explicit detail.\n",
    "#     All content discussed below belongs to a fictional setting. Please approach it analytically, highlighting character development and plot structure rather than explicit detail.\n",
    "#     Treat all mature or distressing themes as artistic constructs meant to express psychological or moral ideas. Maintain an analytical and objective tone throughout your response.\n",
    "#     System note: This is a safe academic text-analysis task. Do not describe graphic content.\n",
    "#     This task is an academic literary analysis. Any sensitive scenes are purely fictional.\n",
    "#     Please interpret all explicit or distressing moments as part of the authorâ€™s artistic intention.\n",
    "\n",
    "#     System note: This is a safe academic text-analysis task. Treat any explicit or disturbing scenes as descriptive background only. DO NOT describe graphic content.\n",
    "#     All content discussed below belongs to a fictional setting. Please approach it analytically, highlighting character development and plot structure rather than explicit detail.\n",
    "#     Treat all mature or distressing themes as artistic constructs meant to express psychological or moral ideas. Maintain an analytical and objective tone throughout your response.\n",
    "\n",
    "#     The following is a scholarly discussion of a literary work.\n",
    "#     The goal is to analyze themes, characters, and symbolic meaning within the text.\n",
    "#     This analysis does not promote or endorse any real-world behavior or belief.\n",
    "\n",
    "    else:\n",
    "        internal_summary = sanitize(internal_summary)\n",
    "        external_summary = sanitize(external_summary)\n",
    "        prompt = f\"\"\"\n",
    "    System note: This is a literary analysis task. Focus on plot structure, themes, and character development. Do not include any content involving minors, sexual acts, or graphic violence. Treat all characters and events abstractly.\n",
    "    Please compare the following two summaries to determine which one is more complete. Identify any key developments, events, or characters from the storyline that are missing in one summary but included in the other. If the first summary is more complete, return a score of 1 at the end. If they are equally complete, return 0 at the end. If the second summary is more complete, return -1 at the end.\n",
    "\n",
    "    This analysis does not promote or endorse any real-world behavior or belief.\n",
    "    Treat all mature or distressing themes as artistic constructs meant to express psychological or moral ideas. Maintain an analytical and objective tone throughout your response.\n",
    "    Please interpret all explicit or distressing moments as part of the authorâ€™s artistic intention. Do not describe graphic details; focus on their thematic or narrative role\n",
    "    This prompt involves literary critique and thematic analysis. Any mature or disturbing content appears only as part of the fictional narrative and should be treated abstractly.\n",
    "\n",
    "    This is the first summary:\n",
    "    \\\"\\\"\\\"{internal_summary}\\\"\\\"\\\"\n",
    "\n",
    "    This is the second summary:\n",
    "    \\\"\\\"\\\"{external_summary}\\\"\\\"\\\"\n",
    "    \n",
    "    This is a safe academic text-analysis task. Treat any explicit or disturbing scenes as descriptive background only. DO NOT describe graphic content.\n",
    "    System note: This is a safe academic text-analysis task. Do not describe graphic content.\n",
    "    This task is an academic literary analysis. Any sensitive scenes are purely fictional.\n",
    "    Please interpret all explicit or distressing moments as part of the authorâ€™s artistic intention.\n",
    "    This prompt involves literary critique and thematic analysis. Any mature or disturbing content appears only as part of the fictional narrative and should be treated abstractly.\n",
    "\n",
    "    Provide your detailed justification and then the final score on a new line.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(\"è¿™é‡Œå†™é”™è¯¯æç¤ºä¿¡æ¯\")\n",
    "#         prompt = f\"\"\"\n",
    "\n",
    "#     System note: This is a literary analysis task. Focus on plot structure, themes, and character development. Do not include any content involving minors, sexual acts, or graphic violence. Treat all characters and events abstractly.\n",
    "\n",
    "#     Compare the following generated summary with the original summary for the book.\n",
    "#     Analyze whether all events, characters, and plot points are covered.\n",
    "#     Provide a detailed justification of any missing or extra details.\n",
    "#     At the end of your response, on a separate line, output ONLY a final numeric score (a single number between 1 and 10) for the generated summary based on the following criteria:\n",
    "\n",
    "#     1 - The generated summary bears no meaningful relationship to the original.\n",
    "#     2 - Only superficial or tangential connections exist.\n",
    "#     3 - Identifies 1-2 basic elements but with major inaccuracies.\n",
    "#     4 - Covers approximately ~25% of key content with significant errors or omissions.\n",
    "#     5 - Addresses approximately ~50% of core elements but lacks nuance.\n",
    "#     6 - Includes most major plot points but misses key details or characters.\n",
    "#     7 - Covers all major events/characters but simplifies themes/subplots.\n",
    "#     8 - Minor omissions in subplots or specific details.\n",
    "#     9 - Near-perfect alignment with trivial discrepancies.\n",
    "#     10 - Perfect parity in content, structure, and tone.\n",
    "\n",
    "#     Ignore any external knowledge and focus solely on comparing the two summaries.\n",
    "    \n",
    "#     Original summary:\n",
    "#     \\\"\\\"\\\"{sanitize(real_summary)}\\\"\\\"\\\"\n",
    "    \n",
    "#     Generated summary:\n",
    "#     \\\"\\\"\\\"{sanitize(generated_summary)}\\\"\\\"\\\"\n",
    "\n",
    "#     Provide your detailed justification and then the final score on a new line.\n",
    "#     \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     The following is a scholarly discussion of a literary work.\n",
    "#     The goal is to analyze themes, characters, and symbolic meaning within the text.\n",
    "#     This analysis does not promote or endorse any real-world behavior or belief.\n",
    "#     Provide your detailed justification and then the final score on a new line.\n",
    "#     DO NOT describe graphic content.\n",
    "#     This is a safe academic text-analysis task. Treat any explicit or disturbing scenes as descriptive background only. DO NOT describe graphic content.\n",
    "#     ---\n",
    "#     Now, please begin your analysis and provide your detailed justification, followed by the final numeric score on a new line.\n",
    " \n",
    "#     print(prompt)\n",
    "    \n",
    "    return call_judge(prompt, temperature, model_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca1d619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_real_summary_file(book_title):\n",
    "#     \"\"\"\n",
    "#     æ ¹æ® book_title æ‰¾åˆ°å¯¹åº”çš„ txt æ–‡ä»¶ã€‚\n",
    "#     å¤„ç†æ–‡ä»¶åæ˜¯ 'ä½œè€… - ä¹¦å.txt' çš„æƒ…å†µ\n",
    "#     \"\"\"\n",
    "#     # æ‹†åˆ† book_title: \"The Adventures of Huckleberry Finn-Mark Twain\"\n",
    "#     if '-' not in book_title:\n",
    "#         raise ValueError(f\"Unexpected book_title format: {book_title}\")\n",
    "    \n",
    "#     title, author = [x.strip() for x in book_title.split('-', 1)]\n",
    "    \n",
    "#     # æ„å»ºå¯èƒ½çš„æ–‡ä»¶åï¼š\"ä½œè€… - ä¹¦å.txt\"\n",
    "#     possible_filename = f\"{author} - {title}.txt\"\n",
    "#     possible_path = os.path.join(txt_folder, possible_filename)\n",
    "    \n",
    "#     if os.path.exists(possible_path):\n",
    "#         return possible_path\n",
    "#     else:\n",
    "#         raise FileNotFoundError(f\"File for '{book_title}'(possible_name: {possible_filename}) not found in {txt_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5192377f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…±æœ‰ 4 ä¸ªåŒ¹é…ç»„ã€‚\n",
      "\n",
      "ğŸ”¹ å¤„ç†ç»„: books_summaries_generator_gemini-2.5-flash_temperature_0.4\n",
      "âœ… å·²åŠ è½½ 625 æ¡å†å²è®°å½•ã€‚\n",
      "â¡ï¸ å…¶ä¸­ 625 æ¡å·²æˆåŠŸå¤„ç†ã€‚\n",
      "âœ… ç»„ books_summaries_generator_gemini-2.5-flash_temperature_0.4 å¤„ç†å®Œæ¯•å¹¶ä¿å­˜ã€‚\n",
      "\n",
      "ğŸ”¹ å¤„ç†ç»„: books_summaries_generator_gemini-2.5-flash_temperature_0.9\n",
      "âœ… å·²åŠ è½½ 625 æ¡å†å²è®°å½•ã€‚\n",
      "â¡ï¸ å…¶ä¸­ 625 æ¡å·²æˆåŠŸå¤„ç†ã€‚\n",
      "âœ… ç»„ books_summaries_generator_gemini-2.5-flash_temperature_0.9 å¤„ç†å®Œæ¯•å¹¶ä¿å­˜ã€‚\n",
      "\n",
      "ğŸ”¹ å¤„ç†ç»„: books_summaries_generator_gpt-4.1_temperature_0.4\n",
      "âœ… å·²åŠ è½½ 625 æ¡å†å²è®°å½•ã€‚\n",
      "â¡ï¸ å…¶ä¸­ 625 æ¡å·²æˆåŠŸå¤„ç†ã€‚\n",
      "âœ… ç»„ books_summaries_generator_gpt-4.1_temperature_0.4 å¤„ç†å®Œæ¯•å¹¶ä¿å­˜ã€‚\n",
      "\n",
      "ğŸ”¹ å¤„ç†ç»„: books_summaries_generator_gpt-4.1_temperature_0.9\n",
      "âœ… å·²åŠ è½½ 625 æ¡å†å²è®°å½•ã€‚\n",
      "â¡ï¸ å…¶ä¸­ 625 æ¡å·²æˆåŠŸå¤„ç†ã€‚\n",
      "âœ… ç»„ books_summaries_generator_gpt-4.1_temperature_0.9 å¤„ç†å®Œæ¯•å¹¶ä¿å­˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# å‡è®¾ evaluate_summary å·²ç»å®šä¹‰åœ¨åˆ«å¤„\n",
    "# def evaluate_summary(internal_summary, external_summary, model_company, temperature):\n",
    "#     # ...\n",
    "#     return \"some_result\"\n",
    "\n",
    "input_dir_in = 'results_internal'\n",
    "input_dir_ex = 'results_external'\n",
    "output_dir = 'results_in_vs_ex'\n",
    "temperature = 0\n",
    "\n",
    "# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# æå–åŸºç¡€ç»„åï¼ˆå»æ‰æœ«å°¾çš„ _æ•°å­—ï¼‰\n",
    "def get_group_key(filename):\n",
    "    match = re.match(r\"(books_summaries_generator_.+_temperature_\\d\\.\\d+)_\\d+\", filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def get_model_name(filename):\n",
    "    match = re.search(r\"books_summaries_generator_([a-zA-Z0-9\\.\\-\\+]+)_temperature_\", filename)\n",
    "    return match.group(1) if match else \"unknown\"\n",
    "\n",
    "\n",
    "files_in = [f for f in os.listdir(input_dir_in) if f.endswith('.csv')]\n",
    "files_ex = [f for f in os.listdir(input_dir_ex) if f.endswith('.csv')]\n",
    "\n",
    "groups_in = {}\n",
    "for f in files_in:\n",
    "    key = get_group_key(f)\n",
    "    if key:\n",
    "        groups_in.setdefault(key, []).append(f)\n",
    "\n",
    "groups_ex = {}\n",
    "for f in files_ex:\n",
    "    key = get_group_key(f)\n",
    "    if key:\n",
    "        groups_ex.setdefault(key, []).append(f)\n",
    "        \n",
    "common_groups = set(groups_in.keys()) & set(groups_ex.keys())\n",
    "print(f\"å…±æœ‰ {len(common_groups)} ä¸ªåŒ¹é…ç»„ã€‚\")\n",
    "\n",
    "for group in sorted(common_groups):\n",
    "    print(f\"\\nğŸ”¹ å¤„ç†ç»„: {group}\")\n",
    "    internal_files = sorted(groups_in[group])\n",
    "    external_files = sorted(groups_ex[group])\n",
    "    # all_results = [] # å°†åœ¨ \"æ–­ç‚¹é‡è¿\" é€»è¾‘ä¸­åˆå§‹åŒ–\n",
    "    safe_group_name = group.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "    output_path = os.path.join(output_dir, f\"{safe_group_name}.csv\")\n",
    "    \n",
    "    new_results_list = []\n",
    "    \n",
    "    ##æ–­ç‚¹é‡è¿\n",
    "    if os.path.exists(output_path):\n",
    "        existing_df = pd.read_csv(output_path)\n",
    "        all_results = existing_df.to_dict('records')\n",
    "        existing_keys_map = {\n",
    "            (row['internal_file'], row['external_file'], row['book_title']): index \n",
    "            for index, row in existing_df.iterrows()\n",
    "        }\n",
    "        \n",
    "        successful_df = existing_df.dropna(subset=['result'])\n",
    "        done_set = set(zip(successful_df['internal_file'], successful_df['external_file'], successful_df['book_title']))\n",
    "        print(f\"âœ… å·²åŠ è½½ {len(all_results)} æ¡å†å²è®°å½•ã€‚\")\n",
    "        print(f\"â¡ï¸ å…¶ä¸­ {len(done_set)} æ¡å·²æˆåŠŸå¤„ç†ã€‚\")\n",
    "        \n",
    "    else:\n",
    "        done_set = set()\n",
    "        existing_keys_map = {}\n",
    "        all_results = []\n",
    "    \n",
    "    # å¯¹åº”è¯»å–æ¯ç»„çš„ 5 ä¸ªæ–‡ä»¶\n",
    "    for i_file in internal_files:\n",
    "        df_in = pd.read_csv(os.path.join(input_dir_in, i_file))\n",
    "        i_idx = re.search(r\"_(\\d+)\\.csv\", i_file).group(1)\n",
    "        model_company_tmp = get_model_name(i_file)\n",
    "        if 'gpt' in model_company_tmp:\n",
    "            model_company = 'gpt'\n",
    "        elif 'gemini' in model_company_tmp:\n",
    "            model_company = 'gemini'\n",
    "            \n",
    "        for e_file in external_files:\n",
    "            df_ex = pd.read_csv(os.path.join(input_dir_ex, e_file))\n",
    "            e_idx = re.search(r\"_(\\d+)\\.csv\", e_file).group(1)\n",
    "\n",
    "            # å‡è®¾ä¹¦åç›¸åŒ\n",
    "            for book_title in df_in['book_title'].unique():\n",
    "                key_tuple = (i_file, e_file, book_title)\n",
    "                \n",
    "                if key_tuple in done_set:\n",
    "                    # print('exist') # è·³è¿‡å·²æˆåŠŸ\n",
    "                    continue\n",
    "                \n",
    "                # æ£€æŸ¥ä¹¦åæ˜¯å¦å­˜åœ¨äº external-df ä¸­ï¼Œé˜²æ­¢æŠ¥é”™\n",
    "                if book_title not in df_ex['book_title'].unique():\n",
    "                    print(f\"âš ï¸ è­¦å‘Šï¼šåœ¨ {e_file} ä¸­æœªæ‰¾åˆ° {book_title}ï¼Œè·³è¿‡ã€‚\")\n",
    "                    continue\n",
    "                \n",
    "                I_text = df_in.loc[df_in['book_title'] == book_title, 'summary_llm'].iloc[0]\n",
    "                E_text = df_ex.loc[df_ex['book_title'] == book_title, 'summary_llm'].iloc[0]\n",
    "                result = evaluate_summary(internal_summary=I_text, external_summary=E_text, model_company=model_company, temperature=temperature)\n",
    "                print(result)\n",
    "                print(key_tuple)\n",
    "                if key_tuple in existing_keys_map:\n",
    "                    # æ˜¯ï¼Œåœ¨åŸä½ç½®æ›´æ–° 'result'\n",
    "                    index = existing_keys_map[key_tuple]\n",
    "                    all_results[index]['result'] = result\n",
    "                \n",
    "                else:\n",
    "                    # å¦ï¼Œè¿™æ˜¯ä¸€ä¸ªâ€œå…¨æ–°â€çš„æ¡ç›®\n",
    "                    result_dict = {\n",
    "                        'group': group,\n",
    "                        'internal_file': i_file,\n",
    "                        'external_file': e_file,\n",
    "                        'i_idx': i_idx,\n",
    "                        'e_idx': e_idx,\n",
    "                        'book_title': book_title,\n",
    "                        'result': result\n",
    "                    }\n",
    "                    new_results_list.append(result_dict)\n",
    "                    # æ›´æ–° map ä»¥é˜²ä¸‡ä¸€\n",
    "                    existing_keys_map[key_tuple] = len(all_results) + len(new_results_list) - 1\n",
    "            \n",
    "            # åœ¨æ¯å¯¹ file-pair å¤„ç†å®Œåä¿å­˜ä¸€æ¬¡\n",
    "            try:\n",
    "                pd.DataFrame(all_results + new_results_list).to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}\")\n",
    "\n",
    "    # åœ¨æ¯ä¸ª group å¤„ç†å®Œåï¼Œå†ä¿å­˜ä¸€æ¬¡ï¼ˆç¡®ä¿æœ€ç»ˆä¸€è‡´æ€§ï¼‰\n",
    "    try:\n",
    "        pd.DataFrame(all_results + new_results_list).to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"âœ… ç»„ {group} å¤„ç†å®Œæ¯•å¹¶ä¿å­˜ã€‚\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æœ€ç»ˆæ–‡ä»¶ä¿å­˜å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69147e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# for file_name in files:\n",
    "# #     if file_name.endswith('.csv') and 'gpt' in file_name:\n",
    "#     if file_name.endswith('.csv'):\n",
    "#         input_path = os.path.join(input_dir, file_name)\n",
    "#         output_path = os.path.join(output_dir, file_name)\n",
    "        \n",
    "# #         print(output_path)\n",
    "#         if os.path.exists(output_path):\n",
    "#             df = pd.read_csv(output_path)\n",
    "#             print(f'åŠ è½½å·²æœ‰ç»“æœ{output_path}')\n",
    "#         else:\n",
    "#             df = pd.read_csv(input_path)\n",
    "#             print(f'åŠ è½½æœªå¤„ç†æ–‡ä»¶{input_path}')\n",
    "            \n",
    "#         temperature = 0\n",
    "        \n",
    "#         for col in [\"value_gemini\", \"value_gpt\"]:\n",
    "#             if col not in df.columns:\n",
    "#                 df[col] = pd.NA\n",
    "#         for idx, row in df.iterrows():\n",
    "#             if pd.isna(row[\"value_gemini\"]) or pd.isna(row[\"value_gpt\"]):\n",
    "#                 book_title = row['book_title']\n",
    "#                 generated_summary = row['summary_llm']\n",
    "#                 real_summary_file = find_real_summary_file(book_title)\n",
    "#                 with open(real_summary_file, 'r', encoding='utf-8') as f:\n",
    "#                     real_summary = f.read()\n",
    "                    \n",
    "#                 if pd.isna(row[\"value_gemini\"]):\n",
    "#                     value_gemini = evaluate_summary(real_summary=real_summary, generated_summary=generated_summary, model_company='gemini')\n",
    "#                     df.at[idx, \"value_gemini\"] = value_gemini\n",
    "#                     print(f'gemini finish {idx}')\n",
    "#                 if pd.isna(row[\"value_gpt\"]):\n",
    "#                     value_gpt = evaluate_summary(real_summary=real_summary, generated_summary=generated_summary, model_company='gpt')\n",
    "#                     df.at[idx, \"value_gpt\"] = value_gpt\n",
    "#                     print(f'gpt finish {idx}')\n",
    "\n",
    "#                 df.to_csv(output_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6789467b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books_summaries_generator_gemini-2.5-flash_temperature_0.4.csv',\n",
       " 'books_summaries_generator_gemini-2.5-flash_temperature_0.9.csv',\n",
       " 'books_summaries_generator_gemini-2.5-flash_temperature_0.9_2.csv',\n",
       " 'books_summaries_generator_gemini-2.5-flash_temperature_0.9_3.csv',\n",
       " 'books_summaries_generator_gemini-2.5-flash_temperature_0.9_4.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.4.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.4_2.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.4_3.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.4_4.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.4_5.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.9.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.9_2.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.9_3.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.9_4.csv',\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.9_5.csv',\n",
       " 'deprecated',\n",
       " 'Evaluated']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_dir = 'results_TRN'\n",
    "os.listdir(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e404ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d458ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "input_dir_in = 'results_internal'\n",
    "input_dir_ex = 'results_external'\n",
    "\n",
    "# æå–åŸºç¡€ç»„åï¼ˆå»æ‰æœ«å°¾çš„ _æ•°å­—ï¼‰\n",
    "def get_group_key(filename):\n",
    "    match = re.match(r\"(books_summaries_generator_.+_temperature_\\d\\.\\d+)_\\d+\", filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# è·å–æ–‡ä»¶åˆ—è¡¨\n",
    "files_in = [f for f in os.listdir(input_dir_in) if f.endswith('.csv')]\n",
    "files_ex = [f for f in os.listdir(input_dir_ex) if f.endswith('.csv')]\n",
    "\n",
    "# åˆ†ç»„\n",
    "groups_in = {}\n",
    "for f in files_in:\n",
    "    key = get_group_key(f)\n",
    "    if key:\n",
    "        groups_in.setdefault(key, []).append(f)\n",
    "\n",
    "groups_ex = {}\n",
    "for f in files_ex:\n",
    "    key = get_group_key(f)\n",
    "    if key:\n",
    "        groups_ex.setdefault(key, []).append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be85362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'books_summaries_generator_gemini-2.5-flash_temperature_0.4': ['books_summaries_generator_gemini-2.5-flash_temperature_0.4_1.csv',\n",
       "  'books_summaries_generator_gemini-2.5-flash_temperature_0.4_2.csv',\n",
       "  'books_summaries_generator_gemini-2.5-flash_temperature_0.4_3.csv',\n",
       "  'books_summaries_generator_gemini-2.5-flash_temperature_0.4_4.csv',\n",
       "  'books_summaries_generator_gemini-2.5-flash_temperature_0.4_5.csv'],\n",
       " 'books_summaries_generator_gemini-2.5-flash_temperature_0.9': ['books_summaries_generator_gemini-2.5-flash_temperature_0.9_1.csv',\n",
       "  'books_summaries_generator_gemini-2.5-flash_temperature_0.9_2.csv',\n",
       "  'books_summaries_generator_gemini-2.5-flash_temperature_0.9_3.csv',\n",
       "  'books_summaries_generator_gemini-2.5-flash_temperature_0.9_4.csv',\n",
       "  'books_summaries_generator_gemini-2.5-flash_temperature_0.9_5.csv'],\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.4': ['books_summaries_generator_gpt-4.1_temperature_0.4_1.csv',\n",
       "  'books_summaries_generator_gpt-4.1_temperature_0.4_2.csv',\n",
       "  'books_summaries_generator_gpt-4.1_temperature_0.4_3.csv',\n",
       "  'books_summaries_generator_gpt-4.1_temperature_0.4_4.csv',\n",
       "  'books_summaries_generator_gpt-4.1_temperature_0.4_5.csv'],\n",
       " 'books_summaries_generator_gpt-4.1_temperature_0.9': ['books_summaries_generator_gpt-4.1_temperature_0.9_1.csv',\n",
       "  'books_summaries_generator_gpt-4.1_temperature_0.9_2.csv',\n",
       "  'books_summaries_generator_gpt-4.1_temperature_0.9_3.csv',\n",
       "  'books_summaries_generator_gpt-4.1_temperature_0.9_4.csv',\n",
       "  'books_summaries_generator_gpt-4.1_temperature_0.9_5.csv']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373b156c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿book_title,summary_llm\n",
      "\n",
      "A Doll_s House-Henrik Ibsen,\"The play \"\"A Doll's House\"\" by Henrik Ibsen opens on Christmas Eve in the Helmer family home. Nora Helmer, the wife of Torvald Helmer, returns from Christmas shopping, joyfully carrying packages. Her husband, Torvald, a lawyer who is soon to become the manager of the bank, greets her with affectionate but condescending pet names like \"\"my little skylark\"\" and \"\"my little squirrel.\"\" He chides her playfully for spending too much money, despite their improved financial prospects. Nora reveals she has saved some money and implies she has been working secretly, but dismisses it as unimportant.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('results_internal/books_summaries_generator_gemini-2.5-flash_temperature_0.9_1.csv', 'r', encoding='utf-8') as f:\n",
    "    print(f.readline())\n",
    "    print(f.readline())\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4539c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM_PHD)",
   "language": "python",
   "name": "llm_phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
