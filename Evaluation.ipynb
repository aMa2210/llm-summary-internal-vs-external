{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import glob\n",
    "import openai\n",
    "from google import genai  # para la API de Gemini\n",
    "from google.genai import types\n",
    "from openai import OpenAI\n",
    "\n",
    "GEMINI_API_KEY = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "def call_gemini(prompt, temperature=0):\n",
    "    \"\"\"\n",
    "    Calls the Gemini model using the Google genai package.\n",
    "    Raises an exception on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(temperature=temperature)\n",
    "        )\n",
    "        text_response = getattr(response, \"text\", None)\n",
    "        if not text_response:\n",
    "            try:\n",
    "                candidates = response.candidates\n",
    "            except Exception:\n",
    "                candidates = None\n",
    "\n",
    "            usage = getattr(response, \"usage_metadata\", None)\n",
    "            prompt_feedback = getattr(response, \"prompt_feedback\", None)\n",
    "\n",
    "            debug = {\n",
    "                \"model\": \"gemini-2.5-flash\",\n",
    "                \"finish_reasons\": [],\n",
    "                \"safety_ratings\": [],\n",
    "                \"usage\": None,\n",
    "                \"prompt_feedback\": None,\n",
    "                \"candidates\": None,\n",
    "            }\n",
    "            if candidates is not None:\n",
    "                infos = []\n",
    "                for c in candidates:\n",
    "                    info = {\n",
    "                        \"finish_reason\": getattr(c, \"finish_reason\", None),\n",
    "                        \"token_count\": getattr(c, \"token_count\", None),\n",
    "                        \"safety_ratings\": getattr(c, \"safety_ratings\", None),\n",
    "                    }\n",
    "                    infos.append(info)\n",
    "                    if hasattr(c, \"safety_ratings\"):\n",
    "                        debug[\"safety_ratings\"].append(c.safety_ratings)\n",
    "                debug[\"candidates\"] = infos\n",
    "\n",
    "            if usage is not None:\n",
    "                debug[\"usage\"] = {\n",
    "                    \"prompt_tokens\": getattr(usage, \"prompt_token_count\", None),\n",
    "                    \"total_tokens\": getattr(usage, \"total_token_count\", None),\n",
    "                    \"candidates_tokens\": getattr(usage, \"candidates_token_count\", None),\n",
    "                }\n",
    "            if prompt_feedback is not None:\n",
    "                debug[\"prompt_feedback\"] = {\n",
    "                    \"blockReason\": getattr(prompt_feedback, \"blockReason\", None),\n",
    "                    \"blockReasonMessage\": getattr(prompt_feedback, \"blockReasonMessage\", None),\n",
    "                    \"safetyRatings\": getattr(prompt_feedback, \"safetyRatings\", None),\n",
    "                }\n",
    "\n",
    "            print(\"Gemini returned empty text. Debug info:\", debug)\n",
    "            return None\n",
    "        \n",
    "        return text_response.strip()\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Gemini error: {str(e)}\")\n",
    "\n",
    "\n",
    "def call_gpt(prompt, model=\"gpt-4.1-2025-04-14\", temperature=0):\n",
    "    \"\"\"\n",
    "    Calls the OpenAI GPT model via API.\n",
    "    Raises an exception on error.\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=8000,\n",
    "        temperature=temperature,\n",
    "    )    \n",
    "    summary = response.choices[0].message.content\n",
    "    \n",
    "    return summary\n",
    "        \n",
    "    \n",
    "def call_judge(prompt, temperature, model_company):\n",
    "    \"\"\"\n",
    "    Unified function to call the chosen judge model.\n",
    "    \"\"\"\n",
    "    if model_company.lower() == \"ollama\":\n",
    "        return call_ollama(JUDGE_MODEL_NAME, prompt, temperature)\n",
    "    elif model_company.lower() == \"gpt\":\n",
    "        return call_gpt(prompt, temperature=temperature)\n",
    "    elif model_company.lower() == \"gemini\":\n",
    "        return call_gemini(prompt, temperature)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown judge model type.\")\n",
    "\n",
    "\n",
    "def sanitize(text):\n",
    "    patterns = {\n",
    "        r'\\bdrown(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bdrowning\\b': '[TRAGIC_EVENT]',\n",
    "\n",
    "        r'\\bgun(?:s)?\\b': '[WEAPON]',\n",
    "        r'\\bgunshot\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\brevolver\\b': '[WEAPON]',\n",
    "        r'\\bshot(?:s|ting)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bshotgun\\b': '[WEAPON]',\n",
    "        r'\\brifle\\b': '[WEAPON]',\n",
    "        r'\\bpistol\\b': '[WEAPON]',\n",
    "        r'\\bfirearm(?:s)?\\b': '[WEAPON]',\n",
    "        r'\\bknife\\b': '[WEAPON]',\n",
    "        r'\\bblade\\b': '[WEAPON]',\n",
    "        r'\\bbomb\\b': '[WEAPON]',\n",
    "        r'\\bexplosive\\b': '[WEAPON]',\n",
    "\n",
    "        r'\\bsuicid(?:e|al|ed)\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\boverdose(?:d)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bhang(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bself[- ]?harm\\b': '[TRAGIC_EVENT]',\n",
    "\n",
    "        r'\\bkill(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bmurder(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bhomicide\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bassault(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\battack(?:ed|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\btortur(?:e|ed|ing)\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\babus(?:e|ed|ing)\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bbeat(?:en|ing)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bslaughter(?:ed)?\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bmassacre(?:d)?\\b': '[TRAGIC_EVENT]',\n",
    "\n",
    "        r'\\bblood(?:y)?\\b': '[TRAGIC_DETAIL]',\n",
    "        r'\\bgore\\b': '[TRAGIC_DETAIL]',\n",
    "        r'\\bcollapsed\\b': '[TRAGIC_EVENT]',\n",
    "        r'\\bcorpse\\b': '[TRAGIC_DETAIL]',\n",
    "        r'\\bwound(?:ed)?\\b': '[TRAGIC_DETAIL]',\n",
    "\n",
    "        r'\\bprostitut(?:e|ion|es)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bbrothel\\b': '[MATURE_SETTING]',\n",
    "        r'\\brape(?:d|ing)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bsexual(?:ly|ity)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bsex(?:ual)? act(?:s)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bmolest(?:ed|ing)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bpedophil(?:e|ia)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bpaedophil(?:e|ia)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bstatutory\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bincest(?:uous)?\\b': '[FAMILY_CONFLICT]',\n",
    "        r'\\bporn(?:ography|o)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bnudit(?:y|ies)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bseduc(?:e|ed|ing|tion)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bproposition(?:ed)?\\b': '[MATURE_CONTENT]',\n",
    "        r'\\beroticism\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bfantas(?:y|ies)\\b': '[MATURE_CONTENT]',\n",
    "        r'\\bdesire\\b': '[MATURE_CONTENT]',\n",
    "        r'\\blonging\\b': '[MATURE_CONTENT]',\n",
    "        r'\\binfatuation\\b': '[MATURE_CONTENT]',\n",
    "        r'\\badmiration\\b': '[MATURE_CONTENT]',\n",
    "\n",
    "        r'\\bchild(?:ren)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bboy(?:s)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bgirl(?:s)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bminor(?:s)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bteen(?:ager|agers)?\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\badolescen(?:t|ce)\\b': '[YOUNG_CHARACTER]',\n",
    "        r'\\bTadzio\\b': '[YOUNG_CHARACTER]',\n",
    "\n",
    "        r'\\bfollows\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\bwatch(?:es|ing)?\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\bstalk(?:s|ing)?\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\balmost openly\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\bobserves\\b': '[ABSTRACT_ACTION]',\n",
    "        r'\\bconsiders\\b': '[ABSTRACT_ACTION]',\n",
    "\n",
    "        r'\\bcholera\\b': '[DISEASE]',\n",
    "        r'\\bplague\\b': '[DISEASE]',\n",
    "        r'\\bdisease\\b': '[DISEASE]',\n",
    "        r'\\bepidemic\\b': '[DISEASE]',\n",
    "\n",
    "        r'\\bterror(?:ist|ism)?\\b': '[VIOLENCE]',\n",
    "\n",
    "        r'\\bdisheveled\\b': '[ABSTRACT_STATE]',\n",
    "        r'\\brepulses\\b': '[ABSTRACT_EMOTION]',\n",
    "        r'\\bcraving\\b': '[ABSTRACT_EMOTION]',\n",
    "        r'\\berodes\\b': '[ABSTRACT_ACTION]',\n",
    "    }\n",
    "\n",
    "    s = text\n",
    "    for pat, repl in patterns.items():\n",
    "        s = re.sub(pat, repl, s, flags=re.IGNORECASE)\n",
    "\n",
    "    return s\n",
    "        \n",
    "        \n",
    "MODIFY_PROMPT=False\n",
    "\n",
    "def evaluate_summary(real_summary, generated_summary, model_company):\n",
    "    \"\"\"\n",
    "    Compares the generated summary with the original summary and produces a detailed justification.\n",
    "    The justification must conclude with a final numeric score (a number between 1 and 10) on a separate line.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not MODIFY_PROMPT:\n",
    "        prompt = f\"\"\"\n",
    "    Compare the following generated summary with the original summary for the book.\n",
    "    Analyze whether all events, characters, and plot points are covered.\n",
    "    Provide a detailed justification of any missing or extra details.\n",
    "    At the end of your response, on a separate line, output ONLY a final numeric score (a single number between 1 and 10) for the generated summary based on the following criteria:\n",
    "\n",
    "    1 - The generated summary bears no meaningful relationship to the original.\n",
    "    2 - Only superficial or tangential connections exist.\n",
    "    3 - Identifies 1-2 basic elements but with major inaccuracies.\n",
    "    4 - Covers approximately ~25% of key content with significant errors or omissions.\n",
    "    5 - Addresses approximately ~50% of core elements but lacks nuance.\n",
    "    6 - Includes most major plot points but misses key details or characters.\n",
    "    7 - Covers all major events/characters but simplifies themes/subplots.\n",
    "    8 - Minor omissions in subplots or specific details.\n",
    "    9 - Near-perfect alignment with trivial discrepancies.\n",
    "    10 - Perfect parity in content, structure, and tone.\n",
    "\n",
    "    Ignore any external knowledge and focus solely on comparing the two summaries.\n",
    "\n",
    "    Original summary:\n",
    "    \\\"\\\"\\\"{real_summary}\\\"\\\"\\\"\n",
    "\n",
    "    Generated summary:\n",
    "    \\\"\\\"\\\"{generated_summary}\\\"\\\"\\\"\n",
    "\n",
    "    Provide your detailed justification and then the final score on a new line.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "\n",
    "    System note: This is a literary analysis task. Focus on plot structure, themes, and character development. Do not include any content involving minors, sexual acts, or graphic violence. Treat all characters and events abstractly.\n",
    "\n",
    "    Compare the following generated summary with the original summary for the book.\n",
    "    Analyze whether all events, characters, and plot points are covered.\n",
    "    Provide a detailed justification of any missing or extra details.\n",
    "    At the end of your response, on a separate line, output ONLY a final numeric score (a single number between 1 and 10) for the generated summary based on the following criteria:\n",
    "\n",
    "    1 - The generated summary bears no meaningful relationship to the original.\n",
    "    2 - Only superficial or tangential connections exist.\n",
    "    3 - Identifies 1-2 basic elements but with major inaccuracies.\n",
    "    4 - Covers approximately ~25% of key content with significant errors or omissions.\n",
    "    5 - Addresses approximately ~50% of core elements but lacks nuance.\n",
    "    6 - Includes most major plot points but misses key details or characters.\n",
    "    7 - Covers all major events/characters but simplifies themes/subplots.\n",
    "    8 - Minor omissions in subplots or specific details.\n",
    "    9 - Near-perfect alignment with trivial discrepancies.\n",
    "    10 - Perfect parity in content, structure, and tone.\n",
    "\n",
    "    Ignore any external knowledge and focus solely on comparing the two summaries.\n",
    "    \n",
    "    Original summary:\n",
    "    \\\"\\\"\\\"{sanitize(real_summary)}\\\"\\\"\\\"\n",
    "    \n",
    "    Generated summary:\n",
    "    \\\"\\\"\\\"{sanitize(generated_summary)}\\\"\\\"\\\"\n",
    "\n",
    "    Provide your detailed justification and then the final score on a new line.\n",
    "    \"\"\"\n",
    "    \n",
    "    return call_judge(prompt, temperature, model_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_real_summary_file(book_title):\n",
    "\n",
    "    if '-' not in book_title:\n",
    "        raise ValueError(f\"Unexpected book_title format: {book_title}\")\n",
    "    \n",
    "    title, author = [x.strip() for x in book_title.split('-', 1)]\n",
    "    \n",
    "    possible_filename = f\"{author} - {title}.txt\"\n",
    "    possible_path = os.path.join(txt_folder, possible_filename)\n",
    "    \n",
    "    if os.path.exists(possible_path):\n",
    "        return possible_path\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File for '{book_title}'(possible_name: {possible_filename}) not found in {txt_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192377f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "txt_folder = \"summaries\"\n",
    "input_dir = 'Results_internal'\n",
    "output_dir = 'Results_internal/Evaluated'\n",
    "files = sorted(os.listdir(input_dir))\n",
    "\n",
    "for file_name in files:\n",
    "\n",
    "    if file_name.endswith('.csv'):\n",
    "        input_path = os.path.join(input_dir, file_name)\n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "        \n",
    "        if os.path.exists(output_path):\n",
    "            df = pd.read_csv(output_path)\n",
    "        else:\n",
    "            df = pd.read_csv(input_path)\n",
    "            \n",
    "        temperature = 0\n",
    "        \n",
    "        for col in [\"value_gemini\", \"value_gpt\"]:\n",
    "            if col not in df.columns:\n",
    "                df[col] = pd.NA\n",
    "        for idx, row in df.iterrows():\n",
    "            if pd.isna(row[\"value_gemini\"]) or pd.isna(row[\"value_gpt\"]):\n",
    "                book_title = row['book_title']\n",
    "                generated_summary = row['summary_llm']\n",
    "                real_summary_file = find_real_summary_file(book_title)\n",
    "                with open(real_summary_file, 'r', encoding='utf-8') as f:\n",
    "                    real_summary = f.read()\n",
    "                    \n",
    "                if pd.isna(row[\"value_gemini\"]):\n",
    "                    value_gemini = evaluate_summary(real_summary=real_summary, generated_summary=generated_summary, model_company='gemini')\n",
    "                    df.at[idx, \"value_gemini\"] = value_gemini\n",
    "                    print(f'gemini finish {idx}')\n",
    "                if pd.isna(row[\"value_gpt\"]):\n",
    "                    value_gpt = evaluate_summary(real_summary=real_summary, generated_summary=generated_summary, model_company='gpt')\n",
    "                    df.at[idx, \"value_gpt\"] = value_gpt\n",
    "                    print(f'gpt finish {idx}')\n",
    "\n",
    "                df.to_csv(output_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b664d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM_PHD)",
   "language": "python",
   "name": "llm_phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
